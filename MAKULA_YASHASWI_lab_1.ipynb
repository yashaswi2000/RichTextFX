{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "MAKULA YASHASWI - lab_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashaswi2000/RichTextFX/blob/master/MAKULA_YASHASWI_lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyynyR7tR3ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFqXz3vPZoNL",
        "colab_type": "code",
        "outputId": "18e56c8f-e7b5-40cc-e46a-1e6da2a58a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE3uL088R3mz",
        "colab_type": "text"
      },
      "source": [
        "#                                               Lab 1 - Weightage - 3%\n",
        "\n",
        "##  Decision Trees and Random Forests\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfPJ74KSR3m0",
        "colab_type": "text"
      },
      "source": [
        "### Dataset used : Amazon Fine food reviews.\n",
        "### Maximum points in lab : 75 pts.\n",
        "#### Important points to remember :\n",
        " 1. Observations for the experiments done should be explained.\n",
        " 2. All the code should be submitted in form of single Jupyter notebook itself.\n",
        " 3. Points for each sub-section are mentioned in appropriate question.\n",
        " 4. Make sure to begin early since few experiments may consume more time to run.\n",
        " 5. You can use Google colab to run in jupyter notebook (https://colab.research.google.com/) How to load data in Google Colab ?(https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92)\n",
        " 6. The lab must be submitted on Google classroom. The code as well as the accompanying observations should be made part of the python notebook.\n",
        " 7. __The lab is due on Feb 7th 11.59pm.__\n",
        " 8. __The lab should be completed individually. Students are expected to follow the honor code of the class.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdtGwHu8R3m0",
        "colab_type": "text"
      },
      "source": [
        "### 1. Go through [scikit learn DecisionTree documentation] : https://scikitlearn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
        "### Explain briefly various options available in corresponding DecisionTree classifier in scikit-learn package. [5 pts]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXrl4f88R3m1",
        "colab_type": "text"
      },
      "source": [
        "# Add your description of the function here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljsPIGV0R3m2",
        "colab_type": "text"
      },
      "source": [
        "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>\n",
        "\n",
        "Number of reviews: 568,454<br>\n",
        "Number of users: 256,059<br>\n",
        "Number of products: 74,258<br>\n",
        "Timespan: Oct 1999 - Oct 2012<br>\n",
        "Number of Attributes/Columns in data: 10 \n",
        "\n",
        "Attribute Information:\n",
        "\n",
        "1. Id\n",
        "2. ProductId - unique identifier for the product\n",
        "3. UserId - unqiue identifier for the user\n",
        "4. ProfileName\n",
        "5. HelpfulnessNumerator - number of users who found the review helpful\n",
        "6. HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
        "7. Score - rating between 1 and 5 \n",
        "8. Time - timestamp for the review\n",
        "9. Summary - brief summary of the review\n",
        "10. Text - text of the review\n",
        "\n",
        "Out of above attributes we will consider <strong>Score as Y or Output variable</strong>, and  <strong>Summary as X or data points.</strong>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCdMb8g2R3m3",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiDPTrdJR3m4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from IPython.display import HTML\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "import pickle\n",
        "import sqlite3\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDBNskRMVMj9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0ddd2452-9662-4813-c462-dad0050bac38"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp1qBNpYVPhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "284ef577-43aa-4d86-e12e-541bb9639f11"
      },
      "source": [
        "cd gdrive/My Drive"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDzia5ftR3m7",
        "colab_type": "text"
      },
      "source": [
        "### 2.  Dataset loading, train test split, print two data points after converting score column into positive, negative class - [5 pts]\n",
        "#### steps :\n",
        " Use score column as the output variable and Summary as the input variable\n",
        " 1. Convert score column as score > 3 - positive class and score <=3 as negative class.\n",
        " 2. Now define train test split as 0.25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6E0eOK34R3m8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1522806f-e9f5-4b51-e30a-17cf7edc46e8"
      },
      "source": [
        "# connecting to the dataset server to download the amazon fine foods dataset. Do not make any changes to the code below\n",
        "con = sqlite3.connect('datasets/database.sqlite')\n",
        "messages = pd.read_sql_query(\"\"\"\n",
        "SELECT Score, Summary\n",
        "FROM Reviews\n",
        "\"\"\", con)\n",
        "\n",
        "# the parition function applied threshold on the rating to label a review as 'positive' or 'negative'.\n",
        "def partition(x):\n",
        "   if x > 3 :\n",
        "     return 1\n",
        "   else :\n",
        "     return 0\n",
        "\n",
        "Score = messages['Score']\n",
        "Score = Score.map(partition)\n",
        "Summary = messages['Summary']\n",
        "\n",
        "# call the function to create the train and test splits according to the ratio 75:25\n",
        "# uncomment and complete the line below\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(Summary, Score, test_size=0.25)\n",
        "\n",
        "# print an example of the dataset after the labeling process\n",
        "print(messages.head(2))\n",
        "tmp = messages\n",
        "tmp['Score'] = tmp['Score'].map(partition)\n",
        "print(tmp.head(2))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Score                Summary\n",
            "0      5  Good Quality Dog Food\n",
            "1      1      Not as Advertised\n",
            "   Score                Summary\n",
            "0      1  Good Quality Dog Food\n",
            "1      0      Not as Advertised\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goHgGTDKVmcO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6ad0e234-d18c-496b-8360-a22d42b299b9"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2vGCQ2tR3nA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# do not change make any changes to the code below. This part of the\n",
        "# code removes stop words and transforms all the words and letters\n",
        "# into a uniform representation. Further, it also removes punctuation\n",
        "# marks.\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_tokens(tokens, stemmer):\n",
        "    stemmed = []\n",
        "    for item in tokens:\n",
        "        stemmed.append(stemmer.stem(item))\n",
        "    return stemmed\n",
        "\n",
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    stems = stem_tokens(tokens, stemmer)\n",
        "    return ' '.join(stems)\n",
        "\n",
        "intab = string.punctuation\n",
        "outtab = \"                                \"\n",
        "trantab = str.maketrans(intab, outtab)\n",
        "\n",
        "corpus = []\n",
        "count_train_x=0\n",
        "for text in train_X:\n",
        "    count_train_x=count_train_x+1\n",
        "    text = text.lower()\n",
        "    text = text.translate(trantab)\n",
        "    text=tokenize(text)\n",
        "    corpus.append(text)\n",
        "        \n",
        "count_test_x=0\n",
        "test_set=[]\n",
        "for text in test_X:\n",
        "    count_test_x=count_test_x+1\n",
        "    text = text.lower()\n",
        "    text = text.translate(trantab)\n",
        "    text=tokenize(text)\n",
        "    test_set.append(text)\n",
        "\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(corpus)        \n",
        "X_test_counts = count_vect.transform(test_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s0fyCxRR3nD",
        "colab_type": "text"
      },
      "source": [
        "### 4. Print before and after using data pre-processing for five data points - [5 pts]\n",
        "For example, following are some outputs that we were able to generate\n",
        "\n",
        " ID | Before preprocessing | After preprocessing \n",
        " -|-|-\n",
        " 45612 | Good Strong Flavor|good strong flavor \n",
        " 180139 | GREAT SIDE DISH | great side dish \n",
        " 541273 | Its agar | it agar \n",
        " 102774 | Great product! | great product\n",
        " 447382 | Love them | love them "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJn6wXDrR3nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data before the processing step is stored in the variable train_X \n",
        "# and the processed data is present in corpus. Print randomly 5 \n",
        "# instances to check the success of the processing step. \n",
        "# insert your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKc3G8ilR3nH",
        "colab_type": "text"
      },
      "source": [
        "### 5. Build a basic decision tree choosing appropriate min_samples_leaf parameter so that tree fits in output cell using Graphviz package [5 pts]\n",
        "Use the decision tree classifier from the sklearn library to learn a decision tree from the training dataet. For now, we would like to only visualize the tree to ensure that we are calling the correct function. Set the min_samples_leaf parameter to a high value (>15000) for learning the tree. This tree will not be accurate, but will be big enough for us to visualize it. Identify the functions in the tree package that will help to visualize the tree and plot it. Below is a sample tree generated when mi_samples_leaf was set to 20000\n",
        "![tree.png](attachment:tree.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlizdC_QR3nI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "outputId": "f0b9ed66-6430-4231-fcb0-ad41f1d07914"
      },
      "source": [
        "from sklearn import tree\n",
        "mod = tree.DecisionTreeClassifier(min_samples_leaf=17000)\n",
        "mod = mod.fit(X_train_counts, train_y)\n",
        "import graphviz \n",
        "dot_data = tree.export_graphviz(mod, out_file=None) \n",
        "graph = graphviz.Source(dot_data)\n",
        "graph \n",
        "#graph.render(\"iris\") "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7fab5fcadf60>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"764pt\" height=\"685pt\"\n viewBox=\"0.00 0.00 763.50 685.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 681)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-681 759.5,-681 759.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"676,-677 514,-677 514,-609 676,-609 676,-677\"/>\n<text text-anchor=\"middle\" x=\"595\" y=\"-661.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[13820] &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"595\" y=\"-646.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.341</text>\n<text text-anchor=\"middle\" x=\"595\" y=\"-631.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 426340</text>\n<text text-anchor=\"middle\" x=\"595\" y=\"-616.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [93109, 333231]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"590,-573 428,-573 428,-505 590,-505 590,-573\"/>\n<text text-anchor=\"middle\" x=\"509\" y=\"-557.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[8813] &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"509\" y=\"-542.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.306</text>\n<text text-anchor=\"middle\" x=\"509\" y=\"-527.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 401739</text>\n<text text-anchor=\"middle\" x=\"509\" y=\"-512.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [75902, 325837]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M566.8404,-608.9465C559.4158,-599.968 551.3185,-590.1758 543.5972,-580.8385\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"546.2928,-578.606 537.2229,-573.13 540.8983,-583.0669 546.2928,-578.606\"/>\n<text text-anchor=\"middle\" x=\"534.865\" y=\"-594.3186\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"755.5,-565.5 608.5,-565.5 608.5,-512.5 755.5,-512.5 755.5,-565.5\"/>\n<text text-anchor=\"middle\" x=\"682\" y=\"-550.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.42</text>\n<text text-anchor=\"middle\" x=\"682\" y=\"-535.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 24601</text>\n<text text-anchor=\"middle\" x=\"682\" y=\"-520.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [17207, 7394]</text>\n</g>\n<!-- 0&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>0&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M623.4871,-608.9465C633.07,-597.491 643.761,-584.711 653.3559,-573.2412\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"656.0646,-575.458 659.7965,-565.5422 650.6955,-570.9666 656.0646,-575.458\"/>\n<text text-anchor=\"middle\" x=\"662.0128\" y=\"-586.7437\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"504,-469 342,-469 342,-401 504,-401 504,-469\"/>\n<text text-anchor=\"middle\" x=\"423\" y=\"-453.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[2220] &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"423\" y=\"-438.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.332</text>\n<text text-anchor=\"middle\" x=\"423\" y=\"-423.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 351241</text>\n<text text-anchor=\"middle\" x=\"423\" y=\"-408.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [73692, 277549]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M480.8404,-504.9465C473.4158,-495.968 465.3185,-486.1758 457.5972,-476.8385\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"460.2928,-474.606 451.2229,-469.13 454.8983,-479.0669 460.2928,-474.606\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"669.5,-461.5 522.5,-461.5 522.5,-408.5 669.5,-408.5 669.5,-461.5\"/>\n<text text-anchor=\"middle\" x=\"596\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.084</text>\n<text text-anchor=\"middle\" x=\"596\" y=\"-431.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 50498</text>\n<text text-anchor=\"middle\" x=\"596\" y=\"-416.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [2210, 48288]</text>\n</g>\n<!-- 1&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>1&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M537.4871,-504.9465C547.07,-493.491 557.761,-480.711 567.3559,-469.2412\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"570.0646,-471.458 573.7965,-461.5422 564.6955,-466.9666 570.0646,-471.458\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"420,-365 258,-365 258,-297 420,-297 420,-365\"/>\n<text text-anchor=\"middle\" x=\"339\" y=\"-349.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[11838] &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"339\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.348</text>\n<text text-anchor=\"middle\" x=\"339\" y=\"-319.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 327389</text>\n<text text-anchor=\"middle\" x=\"339\" y=\"-304.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [73435, 253954]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M395.4953,-400.9465C388.3159,-392.0578 380.4924,-382.3716 373.019,-373.1188\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"375.5727,-370.7102 366.5665,-365.13 370.1271,-375.1086 375.5727,-370.7102\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"578,-357.5 438,-357.5 438,-304.5 578,-304.5 578,-357.5\"/>\n<text text-anchor=\"middle\" x=\"508\" y=\"-342.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.021</text>\n<text text-anchor=\"middle\" x=\"508\" y=\"-327.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 23852</text>\n<text text-anchor=\"middle\" x=\"508\" y=\"-312.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [257, 23595]</text>\n</g>\n<!-- 2&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>2&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M450.8322,-400.9465C460.1048,-389.6012 470.4392,-376.9567 479.7437,-365.5724\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"482.6885,-367.5 486.3069,-357.5422 477.2685,-363.0701 482.6885,-367.5\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"334,-261 172,-261 172,-193 334,-193 334,-261\"/>\n<text text-anchor=\"middle\" x=\"253\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[8596] &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"253\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.366</text>\n<text text-anchor=\"middle\" x=\"253\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 300727</text>\n<text text-anchor=\"middle\" x=\"253\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [72424, 228303]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M310.8404,-296.9465C303.4158,-287.968 295.3185,-278.1758 287.5972,-268.8385\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"290.2928,-266.606 281.2229,-261.13 284.8983,-271.0669 290.2928,-266.606\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"498,-253.5 352,-253.5 352,-200.5 498,-200.5 498,-253.5\"/>\n<text text-anchor=\"middle\" x=\"425\" y=\"-238.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.073</text>\n<text text-anchor=\"middle\" x=\"425\" y=\"-223.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 26662</text>\n<text text-anchor=\"middle\" x=\"425\" y=\"-208.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1011, 25651]</text>\n</g>\n<!-- 3&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>3&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M367.1596,-296.9465C376.5413,-285.6012 386.9973,-272.9567 396.4113,-261.5724\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"399.3763,-263.4791 403.0517,-253.5422 393.9817,-259.0182 399.3763,-263.4791\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"248,-157 86,-157 86,-89 248,-89 248,-157\"/>\n<text text-anchor=\"middle\" x=\"167\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X[19950] &lt;= 0.5</text>\n<text text-anchor=\"middle\" x=\"167\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.381</text>\n<text text-anchor=\"middle\" x=\"167\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 268056</text>\n<text text-anchor=\"middle\" x=\"167\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [68507, 199549]</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M224.8404,-192.9465C217.4158,-183.968 209.3185,-174.1758 201.5972,-164.8385\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"204.2928,-162.606 195.2229,-157.13 198.8983,-167.0669 204.2928,-162.606\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"413.5,-149.5 266.5,-149.5 266.5,-96.5 413.5,-96.5 413.5,-149.5\"/>\n<text text-anchor=\"middle\" x=\"340\" y=\"-134.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.211</text>\n<text text-anchor=\"middle\" x=\"340\" y=\"-119.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 32671</text>\n<text text-anchor=\"middle\" x=\"340\" y=\"-104.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [3917, 28754]</text>\n</g>\n<!-- 4&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>4&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M281.4871,-192.9465C291.07,-181.491 301.761,-168.711 311.3559,-157.2412\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"314.0646,-159.458 317.7965,-149.5422 308.6955,-154.9666 314.0646,-159.458\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"162,-53 0,-53 0,0 162,0 162,-53\"/>\n<text text-anchor=\"middle\" x=\"81\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.378</text>\n<text text-anchor=\"middle\" x=\"81\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 249894</text>\n<text text-anchor=\"middle\" x=\"81\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [63319, 186575]</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M136.6796,-88.9777C128.519,-79.8207 119.6892,-69.9129 111.5179,-60.744\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"114.1042,-58.3854 104.838,-53.2485 108.8783,-63.0427 114.1042,-58.3854\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"327.5,-53 180.5,-53 180.5,0 327.5,0 327.5,-53\"/>\n<text text-anchor=\"middle\" x=\"254\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.408</text>\n<text text-anchor=\"middle\" x=\"254\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 18162</text>\n<text text-anchor=\"middle\" x=\"254\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [5188, 12974]</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M197.6729,-88.9777C205.9285,-79.8207 214.8609,-69.9129 223.1272,-60.744\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"225.7883,-63.0193 229.8848,-53.2485 220.5892,-58.3321 225.7883,-63.0193\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtiIMZ7XR3nK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhIvCofhR3nN",
        "colab_type": "text"
      },
      "source": [
        "### 6. Experiments with different tree parameters\n",
        "#### a. minimum number of samples in a node.  [5 pts]\n",
        "By now we should have all the code in place for learning accurate decision trees. As we discussed in the class, one method to prevent overfitting a decision tree is to put constraints on the number of samples assigned to a split node during training. We had used this parameter to learn extremely short decision trees in the previous step. Let us now vary this parameter and investigate the impact on the train and test accuracy of the model. \n",
        "The first part of the code should loop around different values for min_samples_split and save the resulting train and test accuracy. In the second part, plot a graph with x-axis being the number of samples in the node and accuracy being the y axis. Plot both the train and test accuracies in the same figure. Write a generic function for the plotting as we will use it later for other visualizations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLaopAqXR3nO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b8e5b837-e33d-491c-fb6a-fe338e12b0c7"
      },
      "source": [
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "min_samples_split = [10,50,100,200]\n",
        "for i in min_samples_split:\n",
        "    mod = tree.DecisionTreeClassifier(min_samples_split=i)\n",
        "    mod = mod.fit(X_train_counts, train_y)\n",
        "    train_accuracy_list.append(mod.score(X_train_counts, train_y))\n",
        "    mod_test = tree.DecisionTreeClassifier(min_samples_split=i)\n",
        "    mod_test = mod_test.fit(X_test_counts,test_y)\n",
        "    test_accuracy_list.append(mod_test.score(X_test_counts,test_y))\n",
        "\n",
        "\n",
        "def plot_accuracy(test_accuracy_list,train_accuracy_list, xlabel, ylabel, title):\n",
        "      plt.plot(min_samples_split,train_accuracy_list,label=\"train\")\n",
        "      plt.plot(min_samples_split,test_accuracy_list,label=\"test\")\n",
        "      plt.xlabel(xlabel)\n",
        "      plt.ylabel(ylabel)\n",
        "      plt.title(title)\n",
        "      plt.legend()\n",
        "      plt.show()    \n",
        "\n",
        "plot_accuracy(test_accuracy_list,train_accuracy_list, \"nodes\", \"accuracy\", \"plot\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcYYv/4/DxA0GFDAHREAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgymcsQwR3nR",
        "colab_type": "text"
      },
      "source": [
        "#### b. maximum number of leaf nodes in the tree [5 pts]\n",
        "The tree learner has a parameter max_leaf_nodes. Discuss the role of this parameter during the tree learning. Investigate the impact of this parameter on the train and test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL1k-XZrR3nS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "max_leaf_nodes=1000\n",
        "step_size_2=50\n",
        "for i in range(2, max_leaf_nodes,step_size_2):\n",
        "    # insert your code here\n",
        "\n",
        "plot_accuracy(test_accuracy_list, train_accuracy_list, xlabel, ylabel, title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yehhftWtR3nU",
        "colab_type": "text"
      },
      "source": [
        "#### c. splitting criteria [5 pts]\n",
        "Identify the default splitting critera and experiment with other criterion implemented in the tree package. Report the accuracy on the test dataset as well as other parameters chracterizing the learned decision tree. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNDXEiMJR3nV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# insert your code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0-inCuPR3nY",
        "colab_type": "text"
      },
      "source": [
        "#### d. depth of the decision tree [5 pts]\n",
        "Investigate the impact of depth of the decision tree on the test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEDcE63WR3nZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "maximum_depth=1000\n",
        "step_size=50\n",
        "for i in range(1, maximum_depth,step_size):\n",
        "    #insert your code here\n",
        "\n",
        "plot_accuracy(test_accuracy_list, train_accuracy_list, xlabel, ylabel, title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "249Z_Og6R3nc",
        "colab_type": "text"
      },
      "source": [
        "### 7. Random forest\n",
        "Now, let us explore an ensemble of decision trees - random forest. Fortunately, sklearn has an ensemble library containing the random forest classifier. Let us learn a random forest using both instance and feature bagging independently.\n",
        "#### a. briefly describe the input parameters to the random forest classifier [5 pts]\n",
        "insert your description here\n",
        "#### b. instance bagging [10 pts]\n",
        "As discussed in the class, instances are sampled with replacement to create multiple synthetic training sets. Decision tree is learned for every training set. An ensemble strategy (majority voting) is applied on the output of all the trees for a test instance. Let us vary the number of instances in each bag to learn the random forest and check if there is impact on the performance of the ensemble. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggoJOCowR3nd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import random\n",
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "number_of_instances = [1000,5000,10000,20000]\n",
        "for i in number_of_instances:\n",
        "    # insert your code here\n",
        "\n",
        "plot_accuracy(test_accuracy_list, train_accuracy_list, xlabel, ylabel, title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-zlz6dvR3ng",
        "colab_type": "text"
      },
      "source": [
        "#### c. feature bagging [10 pts]\n",
        "For performing feature bagging, we sample a subset of features from the initial set of features. A decision tree is learned for every training set that contains all the instances characterized by a subset of features. An ensemble strategy is applied for classifying a test instance. In this experiment we will investigate the impact of varying the number of features bagged on the test accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL-uwLl9R3nh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "number_of_features = [1000,10000,15000,20000]\n",
        "for i in number_of_features:\n",
        "    # insert your code here\n",
        "\n",
        "    \n",
        "plot_accuracy(test_accuracy_list ,train_accuracy_list, xlabel, ylabel, title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JIjXDYKR3nk",
        "colab_type": "text"
      },
      "source": [
        "#### d. number of trees in the forest [10 pts]\n",
        "Finally let us vary the number of trees in the random forest. We will use the default random forest classifier and only vary the number of trees learned in the ensemble. Again make your observations on the test accuracy as the number of trees are varied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "wkI1sil2R3nl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_accuracy_list=[]\n",
        "train_accuracy_list=[]\n",
        "number_of_trees = [1,2,5,10,50]\n",
        "for i in number_of_trees:\n",
        "    # insert your code here\n",
        "    \n",
        "plot_accuracy(test_accuracy_list ,train_accuracy_list, xlabel, ylabel, title)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}